[
  {
    "objectID": "posts/2021-11-02_tidyTues_ultraRace.html",
    "href": "posts/2021-11-02_tidyTues_ultraRace.html",
    "title": "TidyTuesday: predict ultra race time",
    "section": "",
    "text": "Load required libraries"
  },
  {
    "objectID": "posts/2021-11-02_tidyTues_ultraRace.html#data-skim",
    "href": "posts/2021-11-02_tidyTues_ultraRace.html#data-skim",
    "title": "TidyTuesday: predict ultra race time",
    "section": "data skim",
    "text": "data skim\nData README is available at here.\n\n\nCode\nultra_rankings <- tuesdata$ultra_rankings\nrace <- tuesdata$race\n\nultra_join <-\n    ultra_rankings %>% \n    left_join(race, by=\"race_year_id\")\n\n\n\n\nCode\nskimr::skim(ultra_join)\n\n\n\nData summary\n\n\nName\nultra_join\n\n\nNumber of rows\n137803\n\n\nNumber of columns\n20\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n9\n\n\nDate\n1\n\n\ndifftime\n1\n\n\nnumeric\n9\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrunner\n0\n1.00\n3\n52\n0\n73629\n0\n\n\ntime\n17791\n0.87\n8\n11\n0\n72840\n0\n\n\ngender\n30\n1.00\n1\n1\n0\n2\n0\n\n\nnationality\n0\n1.00\n3\n3\n0\n133\n0\n\n\nevent\n0\n1.00\n4\n57\n0\n435\n0\n\n\nrace\n0\n1.00\n3\n63\n0\n371\n0\n\n\ncity\n15599\n0.89\n2\n30\n0\n308\n0\n\n\ncountry\n77\n1.00\n4\n17\n0\n60\n0\n\n\nparticipation\n0\n1.00\n4\n5\n0\n4\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n2012-01-14\n2021-09-03\n2017-10-13\n711\n\n\n\nVariable type: difftime\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstart_time\n0\n1\n0 secs\n82800 secs\n05:00:00\n39\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nrace_year_id\n0\n1.00\n26678.70\n20156.18\n2320\n8670.0\n21795.0\n40621\n72496.0\n▇▃▃▂▂\n\n\nrank\n17791\n0.87\n253.56\n390.80\n1\n31.0\n87.0\n235\n1962.0\n▇▁▁▁▁\n\n\nage\n0\n1.00\n46.25\n10.11\n0\n40.0\n46.0\n53\n133.0\n▁▇▂▁▁\n\n\ntime_in_seconds\n17791\n0.87\n122358.26\n37234.38\n3600\n96566.0\n114167.0\n148020\n296806.0\n▁▇▆▁▁\n\n\ndistance\n0\n1.00\n154.08\n39.22\n0\n160.9\n162.6\n168\n179.1\n▁▁▁▁▇\n\n\nelevation_gain\n0\n1.00\n6473.94\n3293.50\n0\n3910.0\n6640.0\n9618\n14430.0\n▅▆▆▇▁\n\n\nelevation_loss\n0\n1.00\n-6512.20\n3305.73\n-14440\n-9618.0\n-6810.0\n-3950\n0.0\n▁▇▆▅▅\n\n\naid_stations\n0\n1.00\n9.58\n7.56\n0\n0.0\n12.0\n16\n56.0\n▇▇▁▁▁\n\n\nparticipants\n0\n1.00\n510.75\n881.25\n0\n0.0\n65.0\n400\n2900.0\n▇▁▁▁▁"
  },
  {
    "objectID": "posts/2021-11-02_tidyTues_ultraRace.html#eda",
    "href": "posts/2021-11-02_tidyTues_ultraRace.html#eda",
    "title": "TidyTuesday: predict ultra race time",
    "section": "EDA",
    "text": "EDA\nWe want to estimate the time (time_in_seconds) for runner to finish based on the features.\n\nthe effect of gender and age\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    filter(!is.na(gender)) %>% \n    filter(age > 10, age < 100) %>% \n    mutate(age_decade = 5* (age %/% 5)) %>% \n    select(time_in_seconds, gender, age, age_decade) %>% \n    group_by(age_decade, gender) %>% \n    summarise(\n        time_in_seconds_sd = sd(time_in_seconds),\n         time_in_seconds = mean(time_in_seconds)\n    ) %>% \n    ggplot(aes(x = age_decade, color=gender, group=gender)) +\n    geom_point(aes(y=time_in_seconds)) +\n    geom_line(aes(y=time_in_seconds)) +\n    geom_errorbar(aes(ymin=time_in_seconds - time_in_seconds_sd, ymax=time_in_seconds + time_in_seconds_sd), width=0.2, alpha=0.7) +\n    scale_color_viridis_d() +\n    labs(x = \"age\", y = \"time (second)\") +\n    scale_y_continuous(labels = scales::label_comma())\n\n\n\n\n\n\n\nthe effect of nationality, age, gender\n\n\nCode\nultra_join %>% \n    mutate(nationality = fct_lump(nationality, prop=0.05)) %>% \n    count(nationality, sort=TRUE) \n\n\n# A tibble: 4 × 2\n  nationality     n\n  <fct>       <int>\n1 Other       50563\n2 USA         47259\n3 FRA         28905\n4 GBR         11076\n\n\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    filter(!is.na(gender)) %>% \n    filter(age > 10, age < 100) %>% \n    mutate(nationality = fct_lump(nationality, prop=0.05)) %>% \n    ggplot(aes(x = age, fill=nationality), group=nationality) +\n    facet_wrap(vars(gender)) +\n    geom_bar(stat=\"density\", alpha=0.5)\n\n\n\n\n\nnationality\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    filter(!is.na(gender)) %>% \n    filter(age > 10, age < 100) %>% \n    mutate(nationality = fct_lump(nationality, prop=0.05)) %>% \n    ggplot(aes(x=fct_reorder(nationality, time_in_seconds), y=time_in_seconds, fill=nationality)) +\n    geom_boxplot() +\n    scale_fill_viridis_d() +\n    labs(x=\"runner's nationality\", fill=NULL, y=\"time (second)\") +\n    scale_y_continuous(labels = scales::label_comma())\n\n\n\n\n\n\n\neffect of distance\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    filter(distance >= 150) %>% \n    ggplot(aes(x=distance, y=time_in_seconds)) +\n    geom_point(alpha=0.1, size=1) +\n    geom_smooth() +\n    labs(y=\"time (second)\") +\n    scale_y_continuous(labels = scales::label_comma())\n\n\n\n\n\n\n\neffect of elevation\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    filter(distance >= 150) %>% \n    mutate(elevation = ifelse(\n        elevation_gain > abs(elevation_loss), elevation_gain,  abs(elevation_loss)\n        )) %>% \n    ggplot(aes(x=elevation , y=time_in_seconds)) +\n    geom_point(alpha=0.1, size=1) +\n    geom_smooth() +\n    labs(y=\"time (second)\") +\n    scale_y_continuous(labels = scales::label_comma())\n\n\n\n\n\n\n\neffect of date\nThe year of the race\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    mutate(\n        race_year=lubridate::year(date), \n        race_month=lubridate::month(date)\n    ) %>% \n    group_by(race_year) %>% \n    summarise(\n        time_in_seconds_sd=mean(time_in_seconds),\n        time_in_seconds=mean(time_in_seconds)\n    ) %>% \n    ungroup() %>% \n    ggplot(aes(x=race_year, y=time_in_seconds)) +\n    geom_point() +\n    geom_line() +\n    geom_errorbar(aes(ymin=time_in_seconds - time_in_seconds_sd, ymax=time_in_seconds + time_in_seconds_sd), alpha=0.5)\n\n\n\n\n\nThe month of race can be the proxy to estimate the season when race was hosted. However, here I did not take the geographic information (hemisphere) into consideration.\n\n\nCode\nultra_join %>% \n    filter(!is.na(time_in_seconds)) %>% \n    mutate(\n        race_year=lubridate::year(date), \n        race_month=lubridate::month(date)\n    ) %>% \n    group_by(race_month) %>% \n    summarise(\n        time_in_seconds_sd=mean(time_in_seconds),\n        time_in_seconds=mean(time_in_seconds)\n    ) %>% \n    ungroup() %>% \n    ggplot(aes(x=race_month, y=time_in_seconds)) +\n    geom_point() +\n    geom_line() +\n    geom_errorbar(aes(ymin=time_in_seconds - time_in_seconds_sd, ymax=time_in_seconds + time_in_seconds_sd), alpha=0.5)"
  },
  {
    "objectID": "posts/2021-11-02_tidyTues_ultraRace.html#learning-models",
    "href": "posts/2021-11-02_tidyTues_ultraRace.html#learning-models",
    "title": "TidyTuesday: predict ultra race time",
    "section": "learning models",
    "text": "learning models\nHere I will perform two distinct models – linear regression and random forest to predict the race time using runner’s gender, age, nationality, elevation and distance of race.\n\ndata budget\ninistal split to train and test\n\n\nCode\nultra_df <- ultra_join %>% \n  filter(!is.na(time_in_seconds)) %>% \n  filter(!is.na(gender)) %>% \n  filter(age > 10, age < 100) %>% \n  filter(distance >= 150) %>% \n  mutate(elevation = ifelse(\n        elevation_gain > abs(elevation_loss), \n        elevation_gain,\n        abs(elevation_loss)\n        )\n  ) %>% \n  select(time_in_seconds, age, gender, nationality, distance, elevation)\n\nset.seed(2021)\nultra_split <- initial_split(ultra_df, strata = time_in_seconds)\nultra_train <- training(ultra_split)\nultra_test <- testing(ultra_split)\n\n\ncreate resamples for cross validation\n\n\nCode\nset.seed(124)\nultra_folds <- vfold_cv(ultra_train, v=10)\n\n\n\n\nrecipes for feature engineer\n\n\nCode\nultra_rec <- recipe(time_in_seconds ~., data = ultra_train) %>% \n  step_other(nationality) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_string2factor(all_nominal_predictors()) %>% \n  # step_dummy(all_nominal_predictors()) %>% \n  I()\n\n# want to test whether dummy variables affect the model behave\nind_rec <- ultra_rec %>% \n  step_dummy(all_nominal_predictors())\n\n\n\n\nfit linear model\nspecify models\n\n\nCode\nlm_spec <- linear_reg() %>% \n  set_engine('lm') %>% \n  set_mode('regression')\n\n\nDoes linear model need dummy variable? Using workflow_set to test\n\n\nCode\nlm_wf <- workflow_set(\n  preproc = list(\"nodummy\"=ultra_rec, \"dummy\"=ind_rec),\n  models = list(lm_spec)\n)\n\nlm_rs <- workflow_map(\n  lm_wf, 'fit_resamples', resamples=ultra_folds\n  )\n\nlm_rs %>% collect_metrics()\n\n\n# A tibble: 4 × 9\n  wflow_id           .config preproc model .metric .esti…¹    mean     n std_err\n  <chr>              <chr>   <chr>   <chr> <chr>   <chr>     <dbl> <int>   <dbl>\n1 nodummy_linear_reg Prepro… AsIs    line… rmse    standa… 2.39e+4    10 6.94e+1\n2 nodummy_linear_reg Prepro… AsIs    line… rsq     standa… 5.66e-1    10 2.73e-3\n3 dummy_linear_reg   Prepro… AsIs    line… rmse    standa… 2.39e+4    10 6.94e+1\n4 dummy_linear_reg   Prepro… AsIs    line… rsq     standa… 5.66e-1    10 2.73e-3\n# … with abbreviated variable name ¹​.estimator\n\n\nBased on the r-square value, the linear model with age, distance, elevation, gender and nationality explained ~57% variance of time_in_seconds.\nUsing dummy variable or not does not change the metrics. In fact, the number of coefficients will be exactly same no matter whether using dummy or not. Below shows coefficients of linear regression by fitting the “nodummy_linear_reg” workflow to the training data.\n\n\nCode\nlm_coef <- lm_rs %>% \n  extract_workflow('nodummy_linear_reg') %>% \n  fit(ultra_train) %>% \n  tidy()\n\nlm_coef\n\n\n# A tibble: 9 × 5\n  term             estimate std.error statistic   p.value\n  <chr>               <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)       142711.     217.      658.  0        \n2 age                 4220.      83.3      50.6 0        \n3 genderW             6315.     236.       26.8 1.82e-157\n4 nationalityGBR    -25432.     389.      -65.3 0        \n5 nationalityJPN    -20211.     406.      -49.8 0        \n6 nationalityUSA    -30025.     302.      -99.6 0        \n7 nationalityother  -19682.     254.      -77.6 0        \n8 distance            2630.      99.2      26.5 2.65e-154\n9 elevation          17421.     117.      149.  0        \n\n\n\n\nCode\nlm_coef %>% \n  filter(term!=\"(Intercept)\") %>% \n  ggplot(aes(x = estimate, y = fct_reorder(term, estimate))) +\n  geom_col(aes(fill=(estimate < 0)), alpha = 0.5) +\n  geom_errorbar(aes(xmin=estimate - std.error, xmax = estimate + std.error), width=0.5) +\n  theme(legend.position = 'none') +\n  labs(fill=NULL, y = NULL)\n\n\n\n\n\nElevation, being a women (compare to being a men), age and distance positively affect race time, while racers from JPN/GBR/USA/other (compare to racers from FRA) finish the race in shorter time.\n\n\nfit random forest model using workflow\nUsing random forest as model to get Resampling results\n\n\nCode\nrf_spec <- rand_forest() %>% \n  set_engine('ranger') %>% \n  set_mode('regression')\n\nrf_wf <- workflow() %>% \n  add_model(rf_spec) %>% \n  add_recipe(ultra_rec)\n\n# resample evaluate \nrf_rs  <- rf_wf %>% \n  fit_resamples(\n    resamples = ultra_folds\n  )\n\n\n\n\nCode\nrf_rs  %>% \n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n  std_err .config             \n  <chr>   <chr>          <dbl> <int>    <dbl> <chr>               \n1 rmse    standard   18535.       10 57.2     Preprocessor1_Model1\n2 rsq     standard       0.738    10  0.00219 Preprocessor1_Model1\n\n\nCompared to linear model shown above, random forest with same predictors can explain more variance of Y (74% vs. 56%) and show smaller rmse (1.8e4 vs. 2.4e4).\n\n\nCode\nbind_rows(\n  rf_rs  %>% \n    collect_metrics() %>% \n    select(.metric, mean, std_err) %>% \n    mutate(model = \"random forest\"),\n  lm_rs  %>% \n    collect_metrics() %>% \n    filter(wflow_id == 'nodummy_linear_reg') %>% \n    select(.metric, mean, std_err) %>% \n    mutate(model = \"linear reg\")\n) %>% \n  ggplot(aes(x = model, y = mean)) +\n  facet_wrap(vars(.metric), scales = 'free') +\n  geom_point() +\n  geom_errorbar(aes(ymin=mean - std_err, ymax=mean + std_err), width=0)\n\n\n\n\n\nNotes: above plot can also be done by autoplot if we perform the comparison between linear regression and random forest models using workflow_set.\n\n\nlast_fit test data using random forest result\n\n\nCode\nrf_final_rs <- rf_wf %>% \n  last_fit(ultra_split)\n\n\n\n\nCode\nrf_final_rs %>% \n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard   18558.    Preprocessor1_Model1\n2 rsq     standard       0.737 Preprocessor1_Model1\n\n\nDifferent from fit_resample results, these metrics are calculated on the test data. The value is very close to the values done on training data (resample data), thus the model is not over-fitted.\n\n\nCode\nfinal_wf <- rf_final_rs %>% \n  extract_workflow()\n\nfinal_wf\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_other()\n• step_normalize()\n• step_string2factor()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      83042 \nNumber of independent variables:  5 \nMtry:                             2 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       342750489 \nR squared (OOB):                  0.7386915 \n\n\nThe above trained workflow from last_fit can be saved in .rda for future prediction\n\n\nCode\n# using final_wf for prediction\nfinal_wf %>% \n  predict(new_data = ultra_train %>% dplyr::slice(1)) \n\n\n# A tibble: 1 × 1\n    .pred\n    <dbl>\n1 108741."
  },
  {
    "objectID": "posts/2021-11-02_tidyTues_ultraRace.html#what-techniques-i-learned",
    "href": "posts/2021-11-02_tidyTues_ultraRace.html#what-techniques-i-learned",
    "title": "TidyTuesday: predict ultra race time",
    "section": "what techniques i learned",
    "text": "what techniques i learned\n\ndeal with high-levels nominal features (fct_lump and step_other) in EDA and modeling\nworkflow_set and map_workflow to create multiple workflows for model and/or recipes comparison.\nfit_resample for cross-validation. The metrics collected from cross-validation results are used for workflow comparison.\nlast_fit model and save trained workflow for future use"
  },
  {
    "objectID": "posts/2022-02-28-glm_coefficients.html",
    "href": "posts/2022-02-28-glm_coefficients.html",
    "title": "Interpreting the coefficients of Generalized Linear Model",
    "section": "",
    "text": "Linear model is the most popular model used in various of fields, due to its simple execution and interpretation. It can be not only used to predict like all other machine learning models. but also widely used for statistical inference due to its simplicity.\nGeneralized Linear Model (GLM), as named indicated, is generalized from linear regression model, and extends linear model default assumptions to include outcome variables following exponential family distribution. It used link function to transform the outcome so that the transformed Y can be represented by linear combination of predictors. Due to this transformation, it makes coefficients interpretation a little confusing. In this blog, I will use four classical examples (Boston, Default, BrainCancer, and Bikeshare from ISLR2 package) to illustrate how to interpret the coefficients of GLM from tidymodels fit tidy outcome in R."
  },
  {
    "objectID": "posts/2022-02-28-glm_coefficients.html#linear-regression",
    "href": "posts/2022-02-28-glm_coefficients.html#linear-regression",
    "title": "Interpreting the coefficients of Generalized Linear Model",
    "section": "Linear regression",
    "text": "Linear regression\nModeling linear regression in R is simple. The following example used dis (weighted mean of distances to five Boston employment centers) as single predictor to predict medv (median value of house in $1000s) in Boston.\n\n\nCode\ndata(Boston)\nlm_m1 <- lm(medv ~ dis, data = Boston)\nsummary(lm_m1)\n\n\n\nCall:\nlm(formula = medv ~ dis, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.016  -5.556  -1.865   2.288  30.377 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  18.3901     0.8174  22.499  < 2e-16 ***\ndis           1.0916     0.1884   5.795 1.21e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.914 on 504 degrees of freedom\nMultiple R-squared:  0.06246,   Adjusted R-squared:  0.0606 \nF-statistic: 33.58 on 1 and 504 DF,  p-value: 1.207e-08\n\n\nBased on coefficients summary, dis is significantly (p-value = 1.21e-08) positively correlated with medv. With 1 unit increase in term of distances to Boston employment centers, the median value of house increase $1091.6 = 1.0916 * 1000.\n\nMultivariate linear regression\nIn multivariate linear regression, when we interpret the coefficients, there are two components taken into account - whether the variables are independent - how to interpret the interaction term\nIn the following example, we model the medv with dis (weighted mean of distances to five Boston employment centers), rm (average number of rooms per dwelling), crim (per capita crime rate by town) and chas (tract bounds river).\nFor practice purpose, I will use tidymodels to build linear model in the multivariate linear regression example.\n\nNo interaction term\nWe starts with no interactions among the predictors.\n\n\nCode\nlm_spec2 <- linear_reg() %>% \n    set_engine('lm') %>% \n    set_mode('regression')\n\nlm_wf2 <- workflow() %>% \n    add_model(lm_spec2) %>% \n    add_formula(medv ~ dis + rm + crim + chas)\n\nlm_fit2 <- lm_wf2 %>% \n    fit(data = Boston)\n\n\nlm_fit2 %>% \n    tidy()\n\n\n# A tibble: 5 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -29.1      2.57      -11.3  1.20e-26\n2 dis            0.201    0.144       1.40 1.62e- 1\n3 rm             8.19     0.406      20.2  9.12e-67\n4 crim          -0.243    0.0350     -6.94 1.19e-11\n5 chas           3.98     1.10        3.63 3.10e- 4\n\n\nIn this model, all predictors except dis show significant correlation with medv (p-value < 0.05). rm and chas are positively while crim is negatively associated with medv. - rm: when keeping all other variables the same, increase 1 room per dwelling on average results in $8,194.4 (8.1944 * 1000) increase in median house value. - chas: when keeping all other variables the same, having tracts bounds to the Charles river increase median house value $3,982.5 (3.9825 * 1000). chas is a dummy variable where = 1 if tract bounds river and =0 otherwise. Thus =0 (tract do not bound to river) is a baseline here. We will discuss more about baseline in later example. - crim: when keeping all other variables the same, 1 unit increase in per capita crime rate will result a decrease of $243.2 (-0.24318 * 1000) in median house value.\n\n\n\nWith interaction term\nBased on common sense, usually the house is smaller when it is closer to city center. Adding interaction term between rm and dis we assumed that the number of room and the distance to business center are not independent. We are testing the hypothesis that the linear relationship between dis and medv was affected by the the rm. This affect can be linear or non-linear, can be negative or positive.\n\n\nCode\nBoston %>% \n    ggplot(aes(rm)) +\n    geom_histogram() +\n    labs(x = 'mean number of room per dwelling')\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nCode\nBoston %>% \n    mutate(rm = as.integer(rm)) %>% \n    ggplot(aes(x=dis, y=medv, color=as.factor(rm))) +\n    geom_smooth(method = 'lm', se = F) +\n    labs(x = 'mean of distances to five Boston employment centers', y= 'median value of owner-occupied homes', color=\"mean number of room per dwelling\") +\n    theme(legend.position = 'bottom')\n\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nThus, we added interaction term between dis and rm. The thumb of rule to use interaction term is hierarchical principle, which means, if we include an interaction in a model, we should also include the main effects, even if the p-values associated with main effect coefficients are not significant. Thus we should always use * instead of : when adding the interaction term. dis*rm means dis + rm + dis:rm.\n\n\nCode\nlm_wf3 <- workflow() %>% \n    add_model(lm_spec2) %>% \n    add_formula(medv ~ dis*rm + crim + chas)\n\nlm_fit3 <- lm_wf3 %>% \n    fit(data = Boston)\n\n\nlm_fit3 %>% \n    tidy()\n\n\n# A tibble: 6 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   -5.03     4.70       -1.07 2.85e- 1\n2 dis           -7.43     1.27       -5.84 9.30e- 9\n3 rm             4.38     0.744       5.89 7.11e- 9\n4 crim          -0.270    0.0341     -7.90 1.80e-14\n5 chas           3.99     1.06        3.77 1.83e- 4\n6 `dis:rm`       1.20     0.198       6.04 3.08e- 9\n\n\nIn this example, all predictors including interaction terms are significant. Interestingly, by adding the interaction between dis and rm, the coefficients associated with dis turn negative from positive when using simple single variable model. To interpret the interaction term,\n\ndis:rm: since interaction term is significant (p-value = 3.077938e-09), thus linear relationship between dis and medv was significantly dependent on the rm, justifying the inclusion of the interaction term in the model.\ndis: when there are 3 ~ 6 rooms in dwelling, one unit further away from five Boston employment centers, it results in $3,835 to $244 ((-7.426 + range(3,6) * 1.197) * 1000) decrease in median value of house. when there are more than 6 (7.426/1.197) rooms in dwelling, one unit further away from five Boston employment centers, it results in at least $953 ((-7.426 + 7 * 1.197) * 1000) increase in median value of house.\nrm: keeping the mean distance to five Boston employment centers as constant dis, one more room in dwelling will increase 1000 * (1.197 * dis + 4.380) in the median value of house. Because the interaction term is positive (1.197), the rate of medv increase in terms of the room number will increase when it is further away from Boston employment centers.\n\n\nWhen to use interaction term\nThe frequently asked question about interaction term is “when should we include interaction term”. The conventional answer is when two predictors are not independent. However, in reality, unless we have very strong prior knowledge about the predictors, it is hard to determine whether two predictors are dependent or not without exploring the data. From the articles/blogs about interaction term I read so far, two methods are generally used to determine whether add interaction term\n\ntry both with and without adding interaction term, if adding interaction term results in significance on interaction term, then use interaction term.\nlike what I did above, plot Y against X1 with X2 as nominal variable (if X2 is not nominal variable itself). If the lines from different X2 levels are parallel, then X1 and X2 are independent and no interaction terms are needed. Otherwise, add interaction term."
  },
  {
    "objectID": "posts/2022-02-28-glm_coefficients.html#logistic-regression",
    "href": "posts/2022-02-28-glm_coefficients.html#logistic-regression",
    "title": "Interpreting the coefficients of Generalized Linear Model",
    "section": "Logistic regression",
    "text": "Logistic regression\nIn the regular linear regression mentioned above, the Y is numeric (aka. quantitative). However, when Y is nominal (aka, qualitative), logistic regression will be used. To make Y still represented by linear combination of predictors, we used logit function (link function) to transform Y (the probability) to \\(ln(\\frac{p}{1-p})\\) (the log odds).\n\\[ln(\\frac{p}{1-p}) = \\sum\\beta X\\] \\(\\beta\\) represents log odds ratio. thus, odds ratio \\(OR = e^\\beta\\).\n\nWhen Y is binomial\nTo evaluate whether a customer will default the credit card default, we build a logistic model with three predictors – whether the customer is a student, the balance on the account and the customer income.\nAgain, for practice purpose, I used tidymodels syntax for demonstration.\n\n\nCode\ndata(\"Default\")\nlr_spec <- logistic_reg() %>% \n    set_engine('glm') %>% \n    set_mode('classification')\n\ndefault_wf <- workflow() %>% \n    add_model(lr_spec) %>% \n    add_formula(default ~ .)\n\ndefault_fit <- default_wf %>% \n    fit(data = Default)\n\ndefault_fit %>% \n    tidy()\n\n\n# A tibble: 4 × 5\n  term            estimate  std.error statistic   p.value\n  <chr>              <dbl>      <dbl>     <dbl>     <dbl>\n1 (Intercept) -10.9        0.492        -22.1   4.91e-108\n2 studentYes   -0.647      0.236         -2.74  6.19e-  3\n3 balance       0.00574    0.000232      24.7   4.22e-135\n4 income        0.00000303 0.00000820     0.370 7.12e-  1\n\n\nIn this model, two predictors (student and balance) are significantly associated with default. To interpret coefficients, we first need to know which is the baseline of default.\n\n\nCode\ncontrasts(Default$default)\n\n\n    Yes\nNo    0\nYes   1\n\n\nBased on the contrasts output, the baseline of default is No. Thus,\n\nstudent: When keeping all other variable constant, compared to non-student (student = 0), a student (student = 1) is less likely to default credit card. The odds ratio is 0.524 (exp(-6.467758e-01)). In other words, if the odds of defaulting credit card as non-student is 1, the odds of defaulting credit card as a student is 0.524 (exp(-6.467758e-01)).\nbalance: When keeping all other variable constant, 1 dollar increase in account balance will result in increasing odds of 1.005 (exp(5.736505e-03)) to default credit card.\n\nNote: above modeling is a bad model since there are high correlation between the predictors (collinearity). I just used it as an example to interpret the coefficients.\n\n\nMultinominal predictors\nUsing multi-nominal predictor diagnosis and other predictors like sex and age time to predict whether the patient survived the brain cancer or not status\n\n\nCode\ndata('BrainCancer')\nBrainCancer <- BrainCancer %>% \n    na.omit()\ncontrasts(BrainCancer$diagnosis)\n\n\n           LG glioma HG glioma Other\nMeningioma         0         0     0\nLG glioma          1         0     0\nHG glioma          0         1     0\nOther              0         0     1\n\n\nIn this example, Meningioma is the baseline for multi-nominal predictor diagnosis.\n\n\nCode\nBrainCancer_rec <- recipe(status ~ ., data = BrainCancer) %>% \n    step_mutate(status = as.factor(status)) %>% \n    step_dummy(diagnosis)\n    \nBrainCancer_wf <- workflow() %>% \n    add_model(lr_spec) %>% \n    add_recipe(BrainCancer_rec)\n\nBrainCancer_fit <- BrainCancer_wf %>% \n    fit(data = BrainCancer)\n\nBrainCancer_fit %>% \n    tidy()\n\n\n# A tibble: 10 × 5\n   term                estimate std.error statistic p.value\n   <chr>                  <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)           3.56      2.57       1.39  0.166  \n 2 sexMale               0.369     0.576      0.640 0.522  \n 3 locSupratentorial     1.09      0.901      1.21  0.227  \n 4 ki                   -0.0695    0.0326    -2.13  0.0332 \n 5 gtv                   0.0382    0.0366     1.04  0.296  \n 6 stereoSRT             0.253     0.771      0.328 0.743  \n 7 time                 -0.0339    0.0155    -2.18  0.0291 \n 8 diagnosis_LG.glioma   1.31      0.844      1.55  0.122  \n 9 diagnosis_HG.glioma   2.37      0.778      3.05  0.00231\n10 diagnosis_Other       0.765     0.940      0.814 0.416  \n\n\nFor multi-nominal predictor diagnosis, the levels (LG glioma, HG glioma and Other) are compared to the baseline Meningioma, and it ends with three terms for coefficient estimation.\nBased on above model, only HG glioma show significant association with survival (p-value < 0.05) when choose Meningioma as baseline. When keeping all other variable constant, compare to Meningioma, the patient with HG glioma are 10 times more (exp(2.37027243)) likely to survive. If we want to compare HG glioma with Other cancer type, simply use exp(2.37027243-0.76482440) to get odds ratio between HG glioma and Other, in which compare to Other, the patient with HG glioma are 5 times more (exp(2.37027243-0.76482440)) likely to survive. However, in this case, we do not know whether this comparison is statistically significant. We can get p-value for this comparison by switching Other as baseline.\n\n\nContrasts matrix\nAnother baseline assignment is using the global average as baseline. To do that, we need to change the contrasts matrix. The following code replace the default contrasts contr.treatment with contr.sum on globalOptions, then use step_dummy from recipe to realize it\n\n\nCode\nBrainCancer_rec %>% \n    prep() %>% \n    bake(new_data = NULL, starts_with(\"diagnosis\")) %>% \n    mutate(diagnosis_orginal = BrainCancer$diagnosis) %>% \n    distinct()\n\n\n# A tibble: 4 × 4\n  diagnosis_LG.glioma diagnosis_HG.glioma diagnosis_Other diagnosis_orginal\n                <dbl>               <dbl>           <dbl> <fct>            \n1                   0                   0               0 Meningioma       \n2                   0                   1               0 HG glioma        \n3                   1                   0               0 LG glioma        \n4                   0                   0               1 Other            \n\n\nCode\ncontr_opt <- getOption(\"contrasts\")\ncontr_opt\n\n\n        unordered           ordered \n\"contr.treatment\"      \"contr.poly\" \n\n\nThe original baseline is Meningioma, each diagnosis_ is compared to the Meningioma.\n\n\nCode\ncontr_sum_opt <- contr_opt\ncontr_sum_opt['unordered'] <- 'contr.sum'\noptions(contrasts = contr_sum_opt)\n\n# my_naming <- function(var, lvl, ordinal = FALSE, sep = \"_\"){\n#     paste(var, levels(BrainCancer$diagnosis)[lvl])\n# }\n\nBrainCancer_rec2 <- recipe(status ~ ., data = BrainCancer) %>% \n    step_mutate(status = as.factor(status)) %>% \n    step_dummy(diagnosis)\n    \nBrainCancer_rec2 %>% \n    prep() %>% \n    bake(new_data = NULL, starts_with(\"diagnosis\")) %>% \n    mutate(diagnosis_orginal = BrainCancer$diagnosis) %>% \n    distinct()\n\n\n# A tibble: 4 × 4\n  diagnosis_X1 diagnosis_X2 diagnosis_X3 diagnosis_orginal\n         <dbl>        <dbl>        <dbl> <fct>            \n1            1            0            0 Meningioma       \n2            0            0            1 HG glioma        \n3            0            1            0 LG glioma        \n4           -1           -1           -1 Other            \n\n\nThus diagnosis_X1, diagnosis_X2 and diagnosis_X3 now represents Meningioma, HG glioma and LG glioma compared to average baseline.\n\n\nCode\nBrainCancer_wf2 <- workflow() %>% \n    add_recipe(BrainCancer_rec2) %>% \n    add_model(lr_spec)\n\nBrainCancer_fit2 <- BrainCancer_wf2 %>% \n    fit(data = BrainCancer)\n\nBrainCancer_fit2 %>% \n    tidy()\n\n\n# A tibble: 10 × 5\n   term         estimate std.error statistic p.value\n   <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)    5.52      2.66       2.07   0.0380\n 2 sex1          -0.184     0.288     -0.640  0.522 \n 3 loc1          -0.545     0.451     -1.21   0.227 \n 4 ki            -0.0695    0.0326    -2.13   0.0332\n 5 gtv            0.0382    0.0366     1.04   0.296 \n 6 stereo1       -0.127     0.386     -0.328  0.743 \n 7 time          -0.0339    0.0155    -2.18   0.0291\n 8 diagnosis_X1  -1.11      0.468     -2.37   0.0177\n 9 diagnosis_X2   0.195     0.594      0.329  0.742 \n10 diagnosis_X3   1.26      0.542      2.33   0.0200\n\n\nBased on the newly trained model BrainCancer_fit2, only Meningioma and LG glioma show significant association with survival (p-value < 0.05) when compared to global average. When keeping all other variable constant, compare to global average, the patient with Meningioma has only 32.9% (exp(-1.11018843)) average survive rate, while the patient with LG glioma are 3.5 times (exp(1.26008400)) more likely to survive.\nMore about coding contrasts in base R syntax can be found at this article.\n\n\nMultinomial outcome\nUsing the same dataset BrainCancer, now I try to predict the diagnosis based on the tumor location (loc), Karnofsky index (ki), Gross tumor volume (gtv) and Stereotactic method (stereo). Here we used multinom_reg() to model multinomial regression\n\n\nCode\noptions(contrasts = contr_opt) # reset contrasts options back to `contr.treatment`\n\nml_spec <- multinom_reg() %>% \n    set_engine('nnet') %>% \n    set_mode('classification')\n\nBrainCancer_rec3 <- recipe(diagnosis ~ loc + ki + gtv + stereo, data = BrainCancer) %>% \n    update_role(diagnosis, new_role = 'outcome') %>% \n    step_normalize(all_numeric_predictors()) %>% \n    step_dummy(all_nominal_predictors())\n\nBrainCancer_wf3 <- workflow() %>% \n    add_model(ml_spec) %>% \n    add_recipe(BrainCancer_rec3)\n\nBrainCancer_fit3 <- BrainCancer_wf3 %>% \n    fit(data = BrainCancer)\n\nBrainCancer_fit3\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: multinom_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nCall:\nnnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)\n\nCoefficients:\n          (Intercept)          ki         gtv loc_Supratentorial stereo_SRT\nLG glioma  -2.3035689  0.23860763 -0.02596393          0.3998414  0.5444269\nHG glioma  -2.5894735  0.03684929  0.15897113          0.9417737  1.3658683\nOther      -0.4158848 -0.29780559  0.14203552         -2.7892771  1.4289732\n\nResidual Deviance: 187.5196 \nAIC: 217.5196 \n\n\nIn the multinomial regression, no p-value were reported. The coefficients represent log odds ratio.\nEach row in the coefficient table corresponds to the model equation. eg. the first row represents the coefficients for LG glioma in comparison to our baseline Meningioma. Each column in the coefficient table corresponds to specific coefficient estimate. Thus, compared to Meningioma, using SRT Stereotactic method is about 4 times (exp(1.3658683)) more likely diagnose HG glioma. A tumor is only 6% (exp(-2.7892771)) chance to be diagnosed as Other instead of Meningioma if it is located at Supratentorial area.\nTo perform above model in base R syntax, please refer to the blog post by Mohit Sharma."
  },
  {
    "objectID": "posts/2022-02-28-glm_coefficients.html#poisson-regression",
    "href": "posts/2022-02-28-glm_coefficients.html#poisson-regression",
    "title": "Interpreting the coefficients of Generalized Linear Model",
    "section": "Poisson regression",
    "text": "Poisson regression\nPoisson regression is used to model count outcome. Unlike regular linear regression, count outcome is not real continuous variable. Instead, it must be positive integer and usually modeled by Poisson distribution rather than normal distribution.\nThe link function for Poisson regression is log function \\(\\ln\\lambda\\) where \\(\\lambda\\) represents the mean of outcome.\nIn the following example, we use Bikeshare data to predict bikers outcome which represents the count of rental bikers\n\n\nCode\ndata('Bikeshare')\n\nBikeshare_rec <- recipe(bikers ~ season + weekday + weathersit + temp + hum + windspeed, data = Bikeshare) %>% \n    step_num2factor(season, levels = c(\"winter\",'spring','summer','fall')) %>%\n    step_num2factor(weekday, transform = function(x) {x+1}, levels = c('sunday','monday','tuesday','wednesday','thursday','friday','saturday')) %>%\n    step_normalize(all_numeric_predictors()) %>%\n    step_dummy(all_nominal_predictors()) %>%\n    I()\n\n# Bikeshare_rec %>% prep() %>% bake(new_data = NULL)\nlibrary(poissonreg)\npr_spec <- poisson_reg() %>% \n    set_engine('glm') %>% \n    set_mode('regression')\n\nBikeshare_wf <- workflow() %>% \n    add_recipe(Bikeshare_rec) %>% \n    add_model(pr_spec)\n\nBikeshare_fit <- Bikeshare_wf %>%\n     parsnip::fit(Bikeshare)\n\nBikeshare_fit %>%\n    tidy()\n\n\n# A tibble: 16 × 5\n   term                       estimate std.error statistic   p.value\n   <chr>                         <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)                  4.58    0.00385   1191.    0        \n 2 temp                         0.426   0.00149    285.    0        \n 3 hum                         -0.256   0.00108   -238.    0        \n 4 windspeed                    0.0404  0.000949    42.6   0        \n 5 season_spring                0.302   0.00384     78.7   0        \n 6 season_summer                0.144   0.00449     32.1   1.12e-226\n 7 season_fall                  0.613   0.00345    177.    0        \n 8 weekday_monday              -0.0464  0.00336    -13.8   1.82e- 43\n 9 weekday_tuesday             -0.0405  0.00336    -12.1   1.42e- 33\n10 weekday_wednesday           -0.0524  0.00342    -15.3   4.88e- 53\n11 weekday_thursday            -0.0804  0.00339    -23.7   2.70e-124\n12 weekday_friday              -0.0151  0.00335     -4.51  6.47e-  6\n13 weekday_saturday            -0.0187  0.00336     -5.58  2.36e-  8\n14 weathersit_cloudy.misty      0.106   0.00223     47.4   0        \n15 weathersit_light.rain.snow  -0.163   0.00425    -38.4   0        \n16 weathersit_heavy.rain.snow  -0.0368  0.167       -0.221 8.25e-  1\n\n\n\n\nCode\ncontrasts(Bikeshare$weathersit)\n\n\n                cloudy/misty light rain/snow heavy rain/snow\nclear                      0               0               0\ncloudy/misty               1               0               0\nlight rain/snow            0               1               0\nheavy rain/snow            0               0               1\n\n\nAll terms except weathersit_heavy.rain.snow are significantly associated with rental bikers number. - when keeping all other variables constant, compared to season_winter, season_spring will increase the mean of rental biker count by 1.35 exp(0.30234965). In other words, there will be 135% bikers rental a bike in spring than winter. - when keeping all other variables constant, every unit increase in temperature will result in on average 1.53 (exp(0.42588059)) rental biker customer.\nnote:above model is not optimal model to predict rental bikers. We use the model without interactions to simplify the question and emphasize interpretation of coefficients in the context of poisson regression . To interpret the coefficients with interaction term, refer to previous regular linear regression example"
  },
  {
    "objectID": "posts/2022-02-28-glm_coefficients.html#final-remarks",
    "href": "posts/2022-02-28-glm_coefficients.html#final-remarks",
    "title": "Interpreting the coefficients of Generalized Linear Model",
    "section": "Final remarks",
    "text": "Final remarks\nIn this post, I focus on interpret the coefficients in three GLM, and show the examples of coefficients associated with both quantitative and qualitative predictors. I also include the examples to interpret coefficients when 1) add interaction term, 2) with multi-nominal outcome and 3) with alternative contrast matrix."
  },
  {
    "objectID": "posts/2022-01-18-chocolate.html",
    "href": "posts/2022-01-18-chocolate.html",
    "title": "TidyTuesday: predict chocolate rating with xgboost",
    "section": "",
    "text": "Load required libraries\nData README is available at here."
  },
  {
    "objectID": "posts/2022-01-18-chocolate.html#clean-data",
    "href": "posts/2022-01-18-chocolate.html#clean-data",
    "title": "TidyTuesday: predict chocolate rating with xgboost",
    "section": "Clean Data",
    "text": "Clean Data\n\n\nCode\nchocolate_raw <- tuesdata$chocolate\nchocolate_raw <- chocolate_raw %>% \n    mutate(cocoa_percent = parse_number(cocoa_percent)) %>% \n    separate(ingredients, c(\"ingredient_num\",\"ingredients\"), sep=\"-\") %>% \n    mutate(\n        ingredient_num=parse_number(ingredient_num),\n        ingredients=str_trim(ingredients)\n    ) %>% \n    mutate(ingredients = map(ingredients, ~str_split(.x, \",\")[[1]])) %>% \n    mutate(most_memorable_characteristics=map(most_memorable_characteristics, ~str_split(.x,\",\")[[1]])) %>% \n    mutate(most_memorable_characteristics=map(most_memorable_characteristics, ~str_trim(.x))) %>% \n    # select(cocoa_percent, ingredient_num, ingredients, most_memorable_characteristics) %>%\n    I()\n\n\n\nConvert gredients to boolean columns\n\nusing unnest to spread out the list column ingredients.\n\n\nCode\ngredients <- chocolate_raw %>% \n    mutate(line_n = row_number()) %>% \n    select(line_n, ingredients) %>% \n    unnest(cols=c(ingredients)) %>% \n    mutate(tmp=1) %>% \n    pivot_wider(names_from=ingredients, values_from=tmp) %>% \n    select(-\"NA\") %>% \n    janitor::clean_names() %>% \n    mutate_at(vars(-line_n), ~ifelse(is.na(.x),0,.x)) %>% \n    I()\n\n\n\nConvert most_memorable_characteristics to boolean columns\n\n\n\nCode\nmost_memorable_characteristics <- chocolate_raw %>% \n    mutate(line_n = row_number()) %>% \n    select(line_n, most_memorable_characteristics) %>% \n    unnest(cols=c(most_memorable_characteristics)) %>% \n    mutate(tmp=1) %>% \n    # distinct(most_memorable_characteristics) %>% \n    # pivot_wider(names_from=most_memorable_characteristics, values_from=tmp) %>% \n    I()\n\n\nThere are 972 most_memorable_characteristics in total\n\n\nCode\nmost_memorable_characteristics %>% \n    # mutate(most_memorable_characteristics = fct_lump_min(most_memorable_characteristics, min=100)) %>% \n    group_by(most_memorable_characteristics) %>% \n    count(sort=T) %>% \n    head(20) %>% \n    ggplot(aes(x=n, y=reorder(most_memorable_characteristics,n))) +\n    geom_col() +\n    geom_text(aes(label=n), color=\"white\", hjust=1) +\n    theme_bw() +\n    labs(x=\"# of chocolates\", y=\"most memorable characteristics\")\n\n\n\n\n\nPick top 12 most_memorable_characteristics to convert to boolean column\n\n\nCode\nmost_memorable_characteristics <- most_memorable_characteristics %>% \n    mutate(most_memorable_characteristics = fct_lump_min(most_memorable_characteristics, min=100)) %>% \n    distinct() %>% \n    pivot_wider(names_from=most_memorable_characteristics, values_from=tmp) %>% \n    mutate_at(vars(-line_n), ~ifelse(is.na(.x),0,.x))\n\n\n\ncreate chocolate_clean data\n\n\n\nCode\nchocolate_clean <-\n    chocolate_raw %>% \n    mutate(line_n=row_number()) %>% \n    select(-ingredients, -most_memorable_characteristics) %>% \n    left_join(gredients) %>%\n    left_join(most_memorable_characteristics) %>%\n    I()"
  },
  {
    "objectID": "posts/2022-01-18-chocolate.html#explore-data",
    "href": "posts/2022-01-18-chocolate.html#explore-data",
    "title": "TidyTuesday: predict chocolate rating with xgboost",
    "section": "Explore Data",
    "text": "Explore Data\nSeveral features are explored in terms of their association with rating.\n\ncountry_of_bean_origin\n\n\n\nCode\nchocolate_clean %>% \n    mutate(country_of_bean_origin = fct_lump(country_of_bean_origin, n=10)) %>% \n    ggplot(aes(x=rating, y=country_of_bean_origin)) +\n    geom_boxplot(aes(fill=country_of_bean_origin)) +\n    theme_bw()\n\n\n\n\n\nBlend and non-blend on country_of_bean_origin shows big difference, thus we convert country_of_bean_origin to country_of_bean_origin_blend\n\n\nCode\nchocolate_clean <- chocolate_clean %>% \n    mutate(country_of_bean_origin_blend = ifelse(country_of_bean_origin==\"Blend\", country_of_bean_origin, \"Non-blend\"))\n\n\n\ncompany_manufacturer and company_location\n\n\n\nCode\nchocolate_clean %>% \n    mutate(company_manufacturer = fct_lump(company_manufacturer, prop=0.01)) %>% \n    ggplot(aes(x=rating, y=reorder(company_manufacturer, rating, median))) +\n    geom_boxplot(aes(fill=company_manufacturer)) +\n    theme_bw() +\n    labs(y=\"company_manufacturer\")\n\n\n\n\n\n\n\nCode\nchocolate_clean %>% \n    mutate(company_location = fct_lump(company_location, n=5)) %>% \n    ggplot(aes(x=rating, y=reorder(company_location, rating))) +\n    geom_boxplot(aes(fill=company_location)) +\n    theme_bw() +\n    labs(y=\"company_location\")\n\n\n\n\n\n\ncocoa_percent\n\n\n\nCode\nchocolate_clean %>% \n    ggplot(aes(x=cocoa_percent, y=rating)) +\n    geom_point(aes(color=as.factor(cocoa))) +\n    theme_bw() +\n    theme(legend.position = \"bottom\") +\n    labs(color=\"cocoa as most_memorable_characteristics\")\n\n\n\n\n\nrating is not as continuous as what i originally imagined. Thus, I convert rating to nominal variable rating_bl using 3 as threshold\n\n\nCode\nchocolate_clean <- chocolate_clean %>% \n    mutate(rating_bl = ifelse(rating >= 3, \">=3\", \"< 3\"))\n\nchocolate_clean %>% \n    group_by(rating_bl) %>% \n    count()\n\n\n# A tibble: 2 × 2\n# Groups:   rating_bl [2]\n  rating_bl     n\n  <chr>     <int>\n1 < 3         566\n2 >=3        1964\n\n\n\n\nCode\nchocolate_clean %>% \n    ggplot(aes(x=cocoa_percent, y=rating_bl)) +\n    geom_boxplot(aes(fill=as.factor(cocoa))) +\n    theme_bw() +\n    labs(y=\"rating\", fill=\"cocoa as most_memorable_characteristics\") +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\nmost_memorable_characteristics\n\n\n\nCode\nchocolate_clean <- chocolate_clean %>% \n    mutate_at(vars(Other:creamy), as.factor)\n\n\nmost_memorable_characteristics like cocoa and creamy positive effect rating, while fatty, earthy, sandy, sour and sweet negatively effect rating.\n\n\nCode\nchocolate_clean %>% \n    select(rating, fatty:creamy) %>% \n    pivot_longer(!rating, names_to=\"most_memorable_characteristics\", values_to=\"yes\") %>%\n    ggplot(aes(y=reorder(most_memorable_characteristics, rating, FUN=median), x=rating)) +\n    geom_boxplot(aes(fill=yes)) +\n    theme_bw() +\n    theme(\n        legend.position = \"bottom\"\n    ) +\n    scale_fill_discrete(labels = c(\"0\"=\"No\", \"1\"=\"Yes\")) +\n    labs(y=\"most_memorable_characteristics\", fill=\"is most_memorable_characteristics?\") +\n    NULL\n\n\n\n\n\n\ningredients\n\n\n\nCode\nchocolate_clean <- \n    chocolate_clean %>% \n    dplyr::rename(igrdt_beans=b, igrdt_sugar=s, igrdt_cocoa=c, igrdt_lecithin=l, igrdt_vanilla=v, igrdt_salt=sa, igrdt_sweeter=s_2) %>% \n    mutate_at(vars(contains(\"igrdt_\")), as.factor)\n\n\ningredient number ingredient_num between 2-3 are associated with higher rating.\n\n\nCode\nchocolate_clean %>% \n    mutate(ingredient_num=as.factor(ingredient_num)) %>% \n    filter(!is.na(ingredient_num)) %>% \n    ggplot(aes(x = ingredient_num, y=rating)) +\n    geom_boxplot()\n\n\n\n\n\ningrediants like beans and sugar positively effect rating, while vanilla, sweeter and salt negatively effect rating.\n\n\nCode\nchocolate_clean %>% \n    select(rating, contains(\"igrdt_\")) %>% \n    pivot_longer(!rating, names_to=\"ingredients\", values_to=\"yes\") %>%\n    mutate(ingredients = gsub(\"igrdt_\",\"\",ingredients)) %>% \n    ggplot(aes(y=reorder(ingredients, rating, FUN=median), x=rating)) +\n    geom_boxplot(aes(fill=yes)) +\n    theme_bw() +\n    theme(\n        legend.position = \"bottom\"\n    ) +\n    scale_fill_discrete(labels = c(\"0\"=\"No\", \"1\"=\"Yes\")) +\n    labs(y=\"ingredients\", fill=\"contain the ingredient?\") +\n    NULL"
  },
  {
    "objectID": "posts/2022-01-18-chocolate.html#ml",
    "href": "posts/2022-01-18-chocolate.html#ml",
    "title": "TidyTuesday: predict chocolate rating with xgboost",
    "section": "ML",
    "text": "ML\nBased on the exploratory analysis, to study the effect on overall rating of chocolates, the following features are selected for building ML models. Plus, using nominal feature rating_bl instead of numeric feature rating as outcome.\n\n\nCode\nchocolate_df <- chocolate_clean %>% \n    select(rating_bl, company_manufacturer, country_of_bean_origin_blend, cocoa_percent, ingredient_num, contains('igrdt_'), cocoa, creamy, fatty, earthy, sandy, sour, sweet) %>% \n    select(-igrdt_cocoa, -igrdt_lecithin) %>% \n    na.omit()\n\n\n\nsplit samples\n\ninitial_split\n\n\n\nCode\nset.seed(123)\nchocolate_split <- initial_split(chocolate_df, strata = rating_bl)\nchocolate_train <- training(chocolate_split)\nchocolate_testing <- testing(chocolate_split)\n\n\n\nresample\n\n\n\nCode\nset.seed(123)\nfolds <- vfold_cv(chocolate_train, v = 10)\nfolds\n\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [1647/184]> Fold01\n 2 <split [1648/183]> Fold02\n 3 <split [1648/183]> Fold03\n 4 <split [1648/183]> Fold04\n 5 <split [1648/183]> Fold05\n 6 <split [1648/183]> Fold06\n 7 <split [1648/183]> Fold07\n 8 <split [1648/183]> Fold08\n 9 <split [1648/183]> Fold09\n10 <split [1648/183]> Fold10\n\n\n\n\nrecipe\n\n\nCode\nchocolate_rec <- \n    recipe(rating_bl ~ ., data = chocolate_train) %>% \n    step_other(company_manufacturer, threshold=0.01, other=\"otherCompany\") %>% \n    # step_mutate_at(c(\"company_manufacturer\",\"country_of_bean_origin_blend\", \"rating_bl\"), fn = ~as.factor(.x)) %>% \n    step_dummy(all_nominal_predictors()) %>% \n    step_zv(all_predictors())\n\nchocolate_rec\n\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         16\n\nOperations:\n\nCollapsing factor levels for company_manufacturer\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()\n\n\ncheck preprocessed data.frame\n\n\nCode\nchocolate_rec %>% \n    prep(new_data = NULL) %>% \n    juice()\n\n\n# A tibble: 1,831 × 20\n   cocoa_percent ingre…¹ ratin…² compa…³ compa…⁴ compa…⁵ compa…⁶ compa…⁷ count…⁸\n           <dbl>   <dbl> <fct>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1            70       4 < 3           0       0       0       0       0       1\n 2            70       4 < 3           0       0       0       0       0       1\n 3            60       3 < 3           0       0       0       0       1       1\n 4            70       2 < 3           0       0       0       0       1       1\n 5            70       2 < 3           0       0       0       0       1       1\n 6            75       4 < 3           0       0       0       0       1       1\n 7            75       4 < 3           0       0       0       0       1       1\n 8            75       5 < 3           0       0       0       0       1       1\n 9            75       5 < 3           0       0       0       0       1       1\n10            65       6 < 3           0       0       0       0       1       1\n# … with 1,821 more rows, 11 more variables: igrdt_sugar_X1 <dbl>,\n#   igrdt_vanilla_X1 <dbl>, igrdt_salt_X1 <dbl>, igrdt_sweeter_X1 <dbl>,\n#   cocoa_X1 <dbl>, creamy_X1 <dbl>, fatty_X1 <dbl>, earthy_X1 <dbl>,\n#   sandy_X1 <dbl>, sour_X1 <dbl>, sweet_X1 <dbl>, and abbreviated variable\n#   names ¹​ingredient_num, ²​rating_bl, ³​company_manufacturer_Arete,\n#   ⁴​company_manufacturer_Bonnat, ⁵​company_manufacturer_Fresco,\n#   ⁶​company_manufacturer_Soma, ⁷​company_manufacturer_otherCompany, …\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\ngrid tune xgboost\n\ncreate model boost_tree\n\nDetails about boost_tree can be found https://parsnip.tidymodels.org/reference/details_boost_tree_xgboost.html\nrequire library xgboost installed.\n\n\nCode\nxg_spec <- \n    boost_tree(\n        mtry=tune(), # the number (or proportion) of predictors that will be randomly sampled\n        min_n=tune() # minimum number of data points in a node\n    ) %>% \n    set_engine(\"xgboost\") %>% # importance=\"permutation\"\n    set_mode('classification')\n\n\n\ndefine grid\n\ngrid_max_entropy, grid_regular, grid_random can be used for quickly specify levels for tuned hyperparameters.\nbe aware that mtry usually requires range parameters, it usually contains the sqrt(predictor_num)\n\n\nCode\nxg_grid <- grid_regular(\n    mtry(range = c(3, 10)),\n    min_n(),\n    levels = 5 # each tune how many levels\n)\n\nxg_grid\n\n\n# A tibble: 25 × 2\n    mtry min_n\n   <int> <int>\n 1     3     2\n 2     4     2\n 3     6     2\n 4     8     2\n 5    10     2\n 6     3    11\n 7     4    11\n 8     6    11\n 9     8    11\n10    10    11\n# … with 15 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\ncreate workflow\n\n\n\nCode\nxg_wf <- workflow() %>% \n    add_model(xg_spec) %>% \n    add_recipe(chocolate_rec)\n\nxg_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_other()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  min_n = tune()\n\nComputational engine: xgboost \n\n\n\ntune model to get result\n\n\n\nCode\nsystem.time(\n    xg_res <- \n        xg_wf %>% \n        tune_grid(\n            resamples = folds,\n            grid = xg_grid\n            )\n    )\n\n\n   user  system elapsed \n 30.965   0.215  31.417 \n\n\n\nevaluate models\n\n\n\nCode\nxg_res %>% \n    collect_metrics() %>% \n    ggplot(aes(x = min_n, y=mean, color=as.factor(mtry))) +\n    facet_wrap(~.metric, scales=\"free\") +\n    geom_point() +\n    geom_line(aes(group=as.factor(mtry))) +\n    theme_bw() +\n    labs(y=\"metrics estimate\", x='minimum number of data points in a node (min_n)', color='the number of predictors that will be randomly sampled (mtry)') +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\nselect hyperparameters and finalize wf\n\nshow_best(metric = ) allows to see the top 5 from xg_res %>% collect_metrics()\nselect_best, select_by_pct_loss, select_by_one_std_err select hyperparameters and corresponding .config to a tibble.\n\n\nCode\nxg_tune_hy <- xg_res %>% \n    select_best(metric = \"accuracy\")\n\nxg_tune_hy\n\n\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1    10    11 Preprocessor1_Model10\n\n\nfinalize model using selected hyperparameters\n\n\nCode\nfinal_wf <- \n  xg_wf %>% \n  finalize_workflow(xg_tune_hy)\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_other()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 10\n  min_n = 11\n\nComputational engine: xgboost \n\n\n\n\nlast_fit model\n\nuse last_fit(split)\n\n\n\nCode\nfinal_fit <- final_wf %>% \n    last_fit(chocolate_split)\n\nfinal_fit\n\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits             id               .metrics .notes   .predictions .workflow \n  <list>             <chr>            <list>   <list>   <list>       <list>    \n1 <split [1831/612]> train/test split <tibble> <tibble> <tibble>     <workflow>\n\n\n\ncollect_metrics for overall data\n\n\n\nCode\nfinal_fit %>% \n    collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.786 Preprocessor1_Model1\n2 roc_auc  binary         0.668 Preprocessor1_Model1\n\n\nmetrics are comparable to training data, so not overfiting.\n\ncollect_predictions for test data\n\n\n\nCode\nfinal_fit %>% \n    collect_predictions()\n\n\n# A tibble: 612 × 7\n   id               `.pred_< 3` `.pred_>=3`  .row .pred_class rating_bl .config \n   <chr>                  <dbl>       <dbl> <int> <fct>       <fct>     <chr>   \n 1 train/test split      0.141        0.859     3 >=3         >=3       Preproc…\n 2 train/test split      0.125        0.875    10 >=3         < 3       Preproc…\n 3 train/test split      0.0668       0.933    11 >=3         < 3       Preproc…\n 4 train/test split      0.156        0.844    17 >=3         >=3       Preproc…\n 5 train/test split      0.0668       0.933    24 >=3         >=3       Preproc…\n 6 train/test split      0.0668       0.933    25 >=3         >=3       Preproc…\n 7 train/test split      0.0711       0.929    32 >=3         >=3       Preproc…\n 8 train/test split      0.236        0.764    42 >=3         < 3       Preproc…\n 9 train/test split      0.491        0.509    46 >=3         < 3       Preproc…\n10 train/test split      0.385        0.615    55 >=3         < 3       Preproc…\n# … with 602 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\nroc_auc and roc_curve on test data\n\ncalculate roc_auc manually on test data\n\n\nCode\nfinal_fit %>%\n  collect_predictions() %>% \n  roc_auc(truth=rating_bl, `.pred_< 3`)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.668\n\n\nplot roc_curve\n\n\nCode\nfinal_fit %>%\n  collect_predictions() %>% \n  roc_curve(truth=rating_bl, `.pred_< 3`) %>% \n  autoplot()\n\n\n\n\n\n\nextract_workflow() to save final_trained_wf\n\n\n\nCode\nfinal_trained_wf <- final_fit %>% \n    extract_workflow()\n\nfinal_trained_wf\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_other()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 21.7 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 0.526315789473684, \n    min_child_weight = 11L, subsample = 1, objective = \"binary:logistic\"), \n    data = x$data, nrounds = 15, watchlist = x$watchlist, verbose = 0, \n    nthread = 1)\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.526315789473684\", min_child_weight = \"11\", subsample = \"1\", objective = \"binary:logistic\", nthread = \"1\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 19 \nniter: 15\nnfeatures : 19 \nevaluation_log:\n    iter training_logloss\n       1        0.6020652\n       2        0.5525599\n---                      \n      14        0.4693209\n      15        0.4688216\n\n\n\nextract_* information from final_trained_wf\n\nextract_fit_engine() is engine-specific model\n\n\n\n\nCode\nfinal_trained_wf %>%\n  extract_fit_engine()\n\n\n##### xgb.Booster\nraw: 21.7 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 0.526315789473684, \n    min_child_weight = 11L, subsample = 1, objective = \"binary:logistic\"), \n    data = x$data, nrounds = 15, watchlist = x$watchlist, verbose = 0, \n    nthread = 1)\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.526315789473684\", min_child_weight = \"11\", subsample = \"1\", objective = \"binary:logistic\", nthread = \"1\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 19 \nniter: 15\nnfeatures : 19 \nevaluation_log:\n    iter training_logloss\n       1        0.6020652\n       2        0.5525599\n---                      \n      14        0.4693209\n      15        0.4688216\n\n\n\nextract_fit_parsnip() is parsnip model object\n\n\n\nCode\nfinal_trained_wf %>%\n  extract_fit_parsnip()\n\n\nparsnip model object\n\n##### xgb.Booster\nraw: 21.7 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 0.526315789473684, \n    min_child_weight = 11L, subsample = 1, objective = \"binary:logistic\"), \n    data = x$data, nrounds = 15, watchlist = x$watchlist, verbose = 0, \n    nthread = 1)\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.526315789473684\", min_child_weight = \"11\", subsample = \"1\", objective = \"binary:logistic\", nthread = \"1\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 19 \nniter: 15\nnfeatures : 19 \nevaluation_log:\n    iter training_logloss\n       1        0.6020652\n       2        0.5525599\n---                      \n      14        0.4693209\n      15        0.4688216\n\n\n\nextract_recipe or extract_preprocessing to get recipe/preprocessing\n\n\n\nCode\nfinal_trained_wf %>% extract_preprocessor()\n\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         16\n\nOperations:\n\nCollapsing factor levels for company_manufacturer\nDummy variables from all_nominal_predictors()\nZero variance filter on all_predictors()\n\n\n\n\nfeature importance\n\nvip() plot top 10\nvi_model() return tibble\n\n\n\nCode\nfinal_trained_wf %>%\n  extract_fit_parsnip() %>% \n  vip()"
  },
  {
    "objectID": "posts/2022-01-18-chocolate.html#final-notes",
    "href": "posts/2022-01-18-chocolate.html#final-notes",
    "title": "TidyTuesday: predict chocolate rating with xgboost",
    "section": "Final notes",
    "text": "Final notes\n\nI convert numeric rating to categorical rating using threshold because, based on the exploratory analysis, the rating values are not continuous.\nThe boost_tree did not produce good estimate for the data.\n\nOther models, like rand_forest(), logistic_reg and svm_linear are worth to try.\nTuning other hyperparameters tree_depth, learning_rate and trees are worth to try. I don’t know which tune-able hyperparameter corresponds to regularization gamma.\n\nJulia Silge posted a screencast and blog of using rand_forest() and svm_linear training rating as linear model on the same dataset."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Learning with sckinta",
    "section": "",
    "text": "R-Ladies Book Club: Chapter 6 linear model selection and regularization\nChapter 6 from ISLR2\n2022-08-18 HTML slides\n\n\n\nR-Ladies Book Club: Introduction to Tidymodels\nThe opening talk at 2022 R-Ladies Philly Book Club\n2022-07-14 HTML slides\n\n\n\nNetwork analysis and visualization\nR-Ladies Philly workshop on network analyses using R igraph object and visualization with ggraph package.\n2019-10-08 PDF slides"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Learning with sckinta",
    "section": "",
    "text": "R\n\n\nGLM\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2022\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ntidyTuesday\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2022\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ntidyTuesday\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2021\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nbash\n\n\nperl\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2020\n\n\n21 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\ndata wrangle\n\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2020\n\n\n5 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nML\n\n\ntidymodels\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2020\n\n\n12 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nshiny\n\n\n\n\n\n\n\n\n\n\n\nMar 30, 2020\n\n\n32 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nbash\n\n\ngit\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2020\n\n\n8 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nnetwork\n\n\nvisualization\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2019\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nnetwork\n\n\n\n\n\n\n\n\n\n\n\nAug 24, 2019\n\n\n4 min\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nR\n\n\nnetwork\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2019\n\n\n9 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Learning with sckinta",
    "section": "",
    "text": "options: eval, echo, output, warning, error, include https://quarto.org/docs/computations/execution-options.html\n\nglobal set options in YAML\n\nexecute:\necho: true\nwarning: false\n\ncode-specific options\n\n#| echo: false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning with sckinta",
    "section": "",
    "text": "Hi! Thank you for stopping by! I am a computational biologist at the Amgen Inc., and volunteer as a co-organizer at Rladies Philly. Originally from China, I came to the U.S. in 2011 and completed my PhD in Biology at the University of Virginia in 2017. Starting as a Perl programmer, I picked up R and Python by taking online courses and attending local meetup workshops. I enjoy learning new programming skills and believe learning is a life-time mission. I would like to dedicate this personal website to sharing the study notes and projects in my learning journey. Hopefully it will help or motivate other self-learners."
  },
  {
    "objectID": "posts/2019-09-04_network_analysis_part3.html",
    "href": "posts/2019-09-04_network_analysis_part3.html",
    "title": "Network visualization - Part 3",
    "section": "",
    "text": "In the previous two posts, we discussed about IGRAPH object and how to manipulate, measure and cluster it. In this final post of network analysis series, I will focus on the network work visualization.\nNetwork visualization are supported by two aspects — the aesthetics of network elements (aka, vertices and edges) and layout of network. There are multiple packages available for these aspects. I will focus on the basic igraph plot which is base R plot and the application of ggraph which use similar syntax comparable to ggplot2."
  },
  {
    "objectID": "posts/2019-09-04_network_analysis_part3.html#vertex-aesthetics",
    "href": "posts/2019-09-04_network_analysis_part3.html#vertex-aesthetics",
    "title": "Network visualization - Part 3",
    "section": "Vertex aesthetics",
    "text": "Vertex aesthetics\nSpecify aesthetics in vertex attribute\n\n\nCode\n# make female and male color different\nv = as_data_frame(g, what=\"vertice\") %>% as_tibble %>% \n  mutate(color=case_when(gender==\"F\" ~ \"red\", gender==\"M\" ~ \"blue\"))\ng = g %>% set_vertex_attr(\"color\", value=v$color)\nplot(g)\n\n\n\n\n\nCode\n# make age as size\nv = v %>% \n  mutate(size=case_when(age < 30 ~ 10, age < 40 & age >30 ~ 20, age > 40 ~ 30))\ng = g %>% set_vertex_attr(\"size\", value=v$size)\nplot(g)\n\n\n\n\n\nThe methods mentioned above can also be done by specify in plot(). One quick example below show the shape aesthetics. Check igraph valid shape names by names(igraph:::.igraph.shapes)\n\n\nCode\n# make gender as shape\nv = v %>% \n  mutate(shape=case_when(gender==\"F\" ~ \"circle\", gender==\"M\" ~ \"rectangle\"))\n\nplot(g, vertex.shape=v$shape)\nlegend('topleft',legend=unique(v$gender),pch=c(21, 22),pt.bg=c(\"red\",\"blue\"))\n\n\n\n\n\nBe aware that the aesthetics specified by attributes can be overwritten by specifying in plot(). In addition, those aesthetics can also be used to apply to all vertices like plot(g, vertex.shape=\"rectangle\"). The attributes to be manipulated in igraph (using base R) are limited. To find all the plotting attributes, try ?plot.igraph or go to https://igraph.org/r/doc/plot.common.html\nWe can also draw attention to certain nodes by mark.groups in plot\n\n\nCode\n# mark dept\ng = g %>% set_vertex_attr(\"dept\",value=c(\"sale\",\"IT\",\"sale\",\"IT\",\"sale\")) %>% \n  set_edge_attr(\"same.dept\",value=c(F,F,T,F,T,T))\nv = as_data_frame(g, \"vertices\")\nplot(g, \n     mark.groups=list(\n       unlist(v %>% filter(dept==\"sale\") %>% select(name)),\n       unlist(v %>% filter(dept==\"IT\") %>% select(name))\n       ), \n     mark.col=c(\"#C5E5E7\",\"#ECD89A\"), mark.border=NA)\n\n\n\n\n\nggraph is a ggplot version of graph plotting. Using graph object as input, it can convert vertice attributes to plot attribute automatically or manually.\n\n\nCode\nv = v %>% \n  mutate(age_range=case_when(age < 30 ~ 20, age < 40 & age >30 ~ 30, age > 40 ~ 40))\ng = g %>% set_vertex_attr(\"age_range\", value=v$age_range)\nggraph(g, layout = \"kk\") +\n  geom_node_point(aes(size=age_range, color=gender), alpha=0.5) +\n  geom_node_text(aes(label=name)) + \n  geom_edge_link() +\n  scale_size_continuous(breaks=c(20,30,40), range = c(2, 6)) +\n  theme_void() \n\n\n\n\n\nAlmost all the {ggplots} theme, scale functions are available for {ggraph}. Refer to rdocumentation for more details."
  },
  {
    "objectID": "posts/2019-09-04_network_analysis_part3.html#edge-aesthetics",
    "href": "posts/2019-09-04_network_analysis_part3.html#edge-aesthetics",
    "title": "Network visualization - Part 3",
    "section": "Edge aesthetics",
    "text": "Edge aesthetics\nSimilar to vertex aesthetics, edge plotting aesthetics can be manipulated both {igraph} default plotting and {ggraph} plotting\n\n\nCode\n# use linetype present whether come from same department, and line width presents friendship\ne = as_data_frame(g, what=\"edges\") %>% as_tibble %>% \n  mutate(width=friendship) %>% \n  mutate(lty=ifelse(same.dept,1,2))\nplot(\n  g %>% set_edge_attr(\"width\",value=e$width) %>% set_edge_attr(\"lty\",value=e$lty),\n  edge.arrow.size=0.8,\n  edge.curved=T\n)\nlegend(\"topleft\", legend=unique(v$gender),pch=21,pt.bg=c(\"red\",\"blue\"), title=\"gender\", box.lty=0)\nlegend(\"left\",legend=unique(e$same.dept),lty=c(1,2), title = \"same.dept\",box.lty=0)\nlegend(\"topright\", legend=sort(unique(e$friendship)), lwd=sort(unique(e$friendship)), title=\"friendship\", box.lty=0)\n\n\n\n\n\nUsing {ggraph} to show edges attribute is much easier.\n\n\nCode\nggraph(g, layout=\"kk\") +\n  geom_edge_link(aes(edge_width=friendship, edge_linetype=same.dept), arrow = arrow(angle=5, length = unit(0.3, \"inches\"))) +\n  geom_node_point(aes(color=gender), size=6) +\n  geom_node_text(aes(label=name), nudge_y = -0.1, nudge_x = -0.1) +\n  scale_edge_width(range = c(1, 2)) +\n  theme_void()"
  },
  {
    "objectID": "posts/2019-09-04_network_analysis_part3.html#facet",
    "href": "posts/2019-09-04_network_analysis_part3.html#facet",
    "title": "Network visualization - Part 3",
    "section": "Facet",
    "text": "Facet\nOne big advantage of {ggraph} is to use facet. It can be facet_edges or facet_nodes or facet_graph. Here I will only show example of facet_nodes.\n\n\nCode\ng = g %>% set_vertex_attr(\"dept\",value=c(\"sale\",\"IT\",\"sale\",\"IT\",\"sale\")) %>% \n  set_edge_attr(\"same.dept\",value=c(F,F,T,F,T,T))\n\n#  facet based on the dept\nggraph(g, layout=\"kk\") +\n  facet_nodes(~dept, drop = F) +\n  geom_edge_link(aes(edge_width=friendship, linetype=same.dept), arrow = arrow(angle=5, length = unit(0.3, \"inches\"))) +\n  geom_node_point(aes(color=gender), size=6) +\n  geom_node_text(aes(label=name), nudge_y = -0.1, nudge_x = -0.1) +\n  scale_edge_width(range = c(1, 2))"
  }
]